---
driver:
  name: vagrant
  customize:
    memory: 4096
    cpuexecutioncap: 90
    cpus: 1
    natdnshostresolver1: "on"
    natdnsproxy1: "on"
    nictype1: "virtio"
<<<<<<< HEAD
  network:
  - ["forwarded_port", {guest: 8080, host: 8987}]
=======
>>>>>>> origin

provisioner:
  name: chef_solo

platforms:
  - name: ubuntu-14.04

suites:
  - name: default
    run_list:
      - recipe[kagent::install]
#      - recipe[hadoop::install]
      - recipe[spark::install]
#      - recipe[hadoop::nn]
#      - recipe[hadoop::dn]
#      - recipe[hadoop::rm]
#      - recipe[hadoop::nm]
      - recipe[spark::master]
      - recipe[spark::worker]
<<<<<<< HEAD
      #- recipe[spark::historyserver]
    attributes:
         java:
            jdk_version: 8
         vagrant: true
         ndb:
            mgmd:
               private_ips: ["10.0.2.15"]
            ndbd:
               private_ips: ["10.0.2.15"]
            mysqld:
               private_ips: ["10.0.2.15"]
            memcached:
               private_ips: ["10.0.2.15"]
            private_ips: ["10.0.2.15"]
            public_ips: ["10.0.2.15"]
            enabled: "true"
            dir: "/tmp"
         hops:
=======
#      - recipe[spark::yarn]
      #- recipe[spark::historyserver]
    attributes:
         java:
           jdk_version: 8
#           install_flavor: oracle
#           oracle:
#             accept_oracle_download_terms: true
         vagrant: true
         hadoop:
#            version: 2.6.0
>>>>>>> origin
            nn:
               private_ips: ["10.0.2.15"]
               public_ips: ["10.0.2.15"]
            dn:
               private_ips: ["10.0.2.15"]
               public_ips: ["10.0.2.15"]
            rm:
               private_ips: ["10.0.2.15"]
               public_ips: ["10.0.2.15"]
            nm:
               private_ips: ["10.0.2.15"]
               public_ips: ["10.0.2.15"]
<<<<<<< HEAD
            use_hopsworks: "false"
            dir: "/tmp"
=======
            use_hadoopworks: "false"
>>>>>>> origin
         spark:
            user: "spark"
            master:
               public_ips: ["10.0.2.15"]
               private_ips: ["10.0.2.15"]
            worker:
               public_ips: ["10.0.2.15"]
               private_ips: ["10.0.2.15"]
            yarn:
               public_ips: ["10.0.2.15"]
               private_ips: ["10.0.2.15"]
            hadoop:
               distribution: "hadoop"
            private_ips: ["10.0.2.15"]
            public_ips: ["10.0.2.15"]
            dir: "/tmp"
         kagent:
            private_ips: ["10.0.2.15"]
            public_ips: ["10.0.2.15"]
            dir: "/tmp"
         private_ips: ["10.0.2.15"]
         public_ips: ["10.0.2.15"]
